{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "from skimage import io, transform\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import math\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['0','1']\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "     transforms.ToPILImage(),\n",
    "     transforms.Resize((28,28)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,0.5,0.5), (0.5, 0.5, 0.5)),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X  [['641.jpg']\n",
      " ['978.jpg']\n",
      " ['800.jpg']\n",
      " ...\n",
      " ['347.jpg']\n",
      " ['1239.jpg']\n",
      " ['1037.jpg']]\n",
      "Calledddd!!!!!!!!  tensor(317) 593.jpg\n",
      "torch.Size([1, 3, 28, 28])\n",
      "X  [['641.jpg']\n",
      " ['978.jpg']\n",
      " ['800.jpg']\n",
      " ...\n",
      " ['347.jpg']\n",
      " ['1239.jpg']\n",
      " ['1037.jpg']]\n",
      "Calledddd!!!!!!!!  tensor(708) 96.jpg\n",
      "torch.Size([1, 3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "class AgeDataSet(Dataset):\n",
    "    def __init__(self,csv,root,transform=None):\n",
    "        self.root=root\n",
    "        self.data=pd.read_csv(csv)\n",
    "        self.X=np.array(self.data.iloc[:,0]).reshape(-1,1)\n",
    "        y=self.data.iloc[:,1]\n",
    "        self.Y=np.array(y).reshape(-1,1)\n",
    "        self.transform=transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self,idx):\n",
    "        print(\"X \",self.X)\n",
    "        print(\"Calledddd!!!!!!!! \",idx,self.X[idx][0])\n",
    "        path=self.root\n",
    "        item=self.X[idx][0]\n",
    "        item=path+item\n",
    "        image = io.imread(item)\n",
    "        label=self.Y[idx][0]\n",
    "        #print(label)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "\n",
    "        return image,label\n",
    "\n",
    "age=AgeDataSet('/work/test/Desktop/python/pytoch/Aero/dataset/train.csv','/work/test/Desktop/python/pytoch/Aero/dataset/training/train/',transform=transform)\n",
    "\n",
    "train_size=int(0.8*len(age))\n",
    "test_size=len(age)-train_size\n",
    "train_dataset, test_dataset = torch.utils.data.dataset.random_split(age, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=1)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1)\n",
    "\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "image,_ = dataiter.next()\n",
    "print(image.shape)\n",
    "image,_ = dataiter.next()\n",
    "print(image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 20, kernel_size= 5, padding =2)\n",
    "        self.fc1 = nn.Linear(14*14*20, 500)\n",
    "        self.fc2 = nn.Linear(500, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 14*14*20)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model=CNN()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "criteria=nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calledddd!!!!!!!!  tensor(594)\n",
      "Calledddd!!!!!!!!  tensor(31)\n",
      "Calledddd!!!!!!!!  tensor(596)\n",
      "Calledddd!!!!!!!!  tensor(517)\n",
      "Calledddd!!!!!!!!  tensor(749)\n",
      "Calledddd!!!!!!!!  tensor(18)\n",
      "Calledddd!!!!!!!!  tensor(746)\n",
      "Calledddd!!!!!!!!  tensor(1266)\n",
      "Calledddd!!!!!!!!  tensor(126)\n",
      "Calledddd!!!!!!!!  tensor(407)\n",
      "Calledddd!!!!!!!!  tensor(214)\n",
      "Calledddd!!!!!!!!  tensor(64)\n",
      "Calledddd!!!!!!!!  tensor(1043)\n",
      "Calledddd!!!!!!!!  tensor(19)\n",
      "Calledddd!!!!!!!!  tensor(889)\n",
      "Calledddd!!!!!!!!  tensor(338)\n",
      "Calledddd!!!!!!!!  tensor(334)\n",
      "Calledddd!!!!!!!!  tensor(1167)\n",
      "Calledddd!!!!!!!!  tensor(274)\n",
      "Calledddd!!!!!!!!  tensor(664)\n",
      "Calledddd!!!!!!!!  tensor(533)\n",
      "Calledddd!!!!!!!!  tensor(49)\n",
      "Calledddd!!!!!!!!  tensor(295)\n",
      "Calledddd!!!!!!!!  tensor(545)\n",
      "Calledddd!!!!!!!!  tensor(470)\n",
      "Calledddd!!!!!!!!  tensor(595)\n",
      "Calledddd!!!!!!!!  tensor(1176)\n",
      "Calledddd!!!!!!!!  tensor(1155)\n",
      "Calledddd!!!!!!!!  tensor(68)\n",
      "Calledddd!!!!!!!!  tensor(843)\n",
      "Calledddd!!!!!!!!  tensor(574)\n",
      "Calledddd!!!!!!!!  tensor(148)\n",
      "Calledddd!!!!!!!!  tensor(1073)\n",
      "Calledddd!!!!!!!!  tensor(632)\n",
      "Calledddd!!!!!!!!  tensor(1067)\n",
      "Calledddd!!!!!!!!  tensor(764)\n",
      "Calledddd!!!!!!!!  tensor(536)\n",
      "Calledddd!!!!!!!!  tensor(228)\n",
      "Calledddd!!!!!!!!  tensor(990)\n",
      "Calledddd!!!!!!!!  tensor(259)\n",
      "Calledddd!!!!!!!!  tensor(701)\n",
      "Calledddd!!!!!!!!  tensor(577)\n",
      "Calledddd!!!!!!!!  tensor(397)\n",
      "Calledddd!!!!!!!!  tensor(159)\n",
      "Calledddd!!!!!!!!  tensor(787)\n",
      "Calledddd!!!!!!!!  tensor(1283)\n",
      "Calledddd!!!!!!!!  tensor(1076)\n",
      "Calledddd!!!!!!!!  tensor(1245)\n",
      "Calledddd!!!!!!!!  tensor(26)\n",
      "Calledddd!!!!!!!!  tensor(365)\n",
      "Calledddd!!!!!!!!  tensor(1163)\n",
      "Calledddd!!!!!!!!  tensor(1151)\n",
      "Calledddd!!!!!!!!  tensor(967)\n",
      "Calledddd!!!!!!!!  tensor(219)\n",
      "Calledddd!!!!!!!!  tensor(544)\n",
      "Calledddd!!!!!!!!  tensor(1)\n",
      "Calledddd!!!!!!!!  tensor(444)\n",
      "Calledddd!!!!!!!!  tensor(1267)\n",
      "Calledddd!!!!!!!!  tensor(1001)\n",
      "Calledddd!!!!!!!!  tensor(362)\n",
      "Calledddd!!!!!!!!  tensor(530)\n",
      "Calledddd!!!!!!!!  tensor(320)\n",
      "Calledddd!!!!!!!!  tensor(799)\n",
      "Calledddd!!!!!!!!  tensor(46)\n",
      "Calledddd!!!!!!!!  tensor(669)\n",
      "Calledddd!!!!!!!!  tensor(838)\n",
      "Calledddd!!!!!!!!  tensor(568)\n",
      "Calledddd!!!!!!!!  tensor(792)\n",
      "Calledddd!!!!!!!!  tensor(514)\n",
      "Calledddd!!!!!!!!  tensor(1287)\n",
      "Calledddd!!!!!!!!  tensor(1101)\n",
      "Calledddd!!!!!!!!  tensor(1206)\n",
      "Calledddd!!!!!!!!  tensor(597)\n",
      "Calledddd!!!!!!!!  tensor(389)\n",
      "Calledddd!!!!!!!!  tensor(538)\n",
      "Calledddd!!!!!!!!  tensor(351)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-80105895fc2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriteria\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mave_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m199\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# print every 200 mini-batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     99\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'momentum_buffer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                         \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import skimage\n",
    "for epoch in range(5):\n",
    "    ave_loss=0.0\n",
    "    \n",
    "    for i,data in enumerate(train_loader,0):\n",
    "        inputs,labels =data\n",
    "        #print(inputs.shape)\n",
    "        inputs=torch.from_numpy(np.array(inputs))\n",
    "        labels=torch.from_numpy(np.array(labels))\n",
    "        optimizer.zero_grad()\n",
    "        output=model(inputs)\n",
    "        \n",
    "        \n",
    "        loss=criteria(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ave_loss+=loss.item()\n",
    "        if i%200==199:    # print every 200 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, ave_loss / 100))\n",
    "            ave_loss = 0.0\n",
    "correct=0\n",
    "total=0\n",
    "with torch.no_grad():\n",
    "    for inputs,labels in test_loader:\n",
    "#         inputs=data['image']\n",
    "#         labels=data['label']\n",
    "        \n",
    "        inputs=torch.from_numpy(np.array(inputs))\n",
    "        labels=torch.from_numpy(np.array(labels))\n",
    "        outputs=model(inputs)\n",
    "        _,predicted=torch.max(outputs.data,1)\n",
    "        total+=labels.size(0)\n",
    "        correct+=(predicted==labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the  test images: %0.6f %%' % (\n",
    "    100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
