{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "import torchvision.datasets as dsets\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "plt.ion()  \n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"Using CUDA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data which has folder name as a label and do transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53177\n"
     ]
    }
   ],
   "source": [
    "train_dir = './fruits-360/Training/'\n",
    "normalize = transforms.Normalize(mean=[0.0, 0.0, 0.0],\n",
    "                                 std=[1, 1, 1])\n",
    "\n",
    "train_dataset = dsets.ImageFolder(\n",
    "    train_dir,\n",
    "    transforms.Compose([\n",
    "        # Data augmentation is a good practice for the train set\n",
    "        # Here, we randomly crop the image to 224x224 and\n",
    "        # randomly flip it horizontally. \n",
    "     #transforms.ToPILImage(),\n",
    "     transforms.Resize((224,224)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,0.5,0.5), (0.5, 0.5, 0.5)),\n",
    "    ]))\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperParam Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diving data into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(train_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lenght of loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53177\n",
      "5318\n",
      "1330\n"
     ]
    }
   ],
   "source": [
    "#print(\"num of classes \",train_loader.classes)\n",
    "print(len(train_dataset))\n",
    "print(len(train_loader))\n",
    "print(len(validation_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# freezing feature extractor layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=False)\n",
    "#set_parameter_requires_grad(model, True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 130)\n",
    "input_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criteria=nn.CrossEntropyLoss()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   500] loss: 17.531\n",
      "[1,  1000] loss: 9.812\n",
      "[1,  1500] loss: 6.963\n",
      "[1,  2000] loss: 4.993\n",
      "[1,  2500] loss: 3.947\n",
      "[1,  3000] loss: 3.033\n",
      "[1,  3500] loss: 2.210\n",
      "[1,  4000] loss: 1.788\n",
      "[1,  4500] loss: 1.389\n",
      "[1,  5000] loss: 1.273\n",
      "[2,   500] loss: 0.901\n",
      "[2,  1000] loss: 0.686\n",
      "[2,  1500] loss: 0.685\n",
      "[2,  2000] loss: 0.564\n",
      "[2,  2500] loss: 0.474\n",
      "[2,  3000] loss: 0.589\n",
      "[2,  3500] loss: 0.326\n",
      "[2,  4000] loss: 0.308\n",
      "[2,  4500] loss: 0.307\n",
      "[2,  5000] loss: 0.326\n",
      "[3,   500] loss: 0.226\n",
      "[3,  1000] loss: 0.135\n",
      "[3,  1500] loss: 0.108\n",
      "[3,  2000] loss: 0.152\n",
      "[3,  2500] loss: 0.177\n",
      "[3,  3000] loss: 0.120\n",
      "[3,  3500] loss: 0.163\n",
      "[3,  4000] loss: 0.135\n",
      "[3,  4500] loss: 0.200\n",
      "[3,  5000] loss: 0.162\n",
      "[4,   500] loss: 0.050\n",
      "[4,  1000] loss: 0.141\n",
      "[4,  1500] loss: 0.050\n",
      "[4,  2000] loss: 0.021\n",
      "[4,  2500] loss: 0.064\n",
      "[4,  3000] loss: 0.059\n",
      "[4,  3500] loss: 0.068\n",
      "[4,  4000] loss: 0.049\n",
      "[4,  4500] loss: 0.082\n",
      "[4,  5000] loss: 0.091\n",
      "[5,   500] loss: 0.077\n",
      "[5,  1000] loss: 0.016\n",
      "[5,  1500] loss: 0.041\n",
      "[5,  2000] loss: 0.124\n",
      "[5,  2500] loss: 0.064\n",
      "[5,  3000] loss: 0.019\n",
      "[5,  3500] loss: 0.042\n",
      "[5,  4000] loss: 0.029\n",
      "[5,  4500] loss: 0.020\n",
      "[5,  5000] loss: 0.021\n"
     ]
    }
   ],
   "source": [
    "#import skimage\n",
    "for epoch in range(5):\n",
    "    ave_loss=0.0\n",
    "    \n",
    "    for i,data in enumerate(train_loader,0):\n",
    "        inputs,labels =data\n",
    "        #print(inputs.shape)\n",
    "        inputs=torch.from_numpy(np.array(inputs))\n",
    "        labels=torch.from_numpy(np.array(labels))\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output=model(inputs)\n",
    "        \n",
    "        \n",
    "        loss=criteria(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        ave_loss+=loss.item()\n",
    "        if i%500==499:    # print every 200 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, ave_loss / 100))\n",
    "            ave_loss = 0.0\n",
    "correct=0\n",
    "total=0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the  test images: 99.943583 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for inputs,labels in validation_loader:\n",
    "#         inputs=data['image']\n",
    "#         labels=data['label']\n",
    "        \n",
    "        inputs=torch.from_numpy(np.array(inputs))\n",
    "        labels=torch.from_numpy(np.array(labels))\n",
    "        outputs=model(inputs.cuda())\n",
    "        _,predicted=torch.max(outputs.data,1)\n",
    "        total+=labels.size(0)\n",
    "        correct+=(predicted==labels.cuda()).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the  test images: %0.6f %%' % (\n",
    "    100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
